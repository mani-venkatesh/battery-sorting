{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell vs Cylinder Battery Classifier**  *Version 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Avoid OOM Errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # For import issues: https://github.com/ultralytics/ultralytics/issues/1270\n",
    "import imghdr\n",
    "\n",
    "data_dir = 'geo_data' # Currently data is google images for 'cylinder batteries' and 'coin cell batteries'\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']\n",
    "\n",
    "## Test\n",
    "# import matplotlib.pyplot as plt\n",
    "# test_img = cv2.imread(os.path.join('data','coin','button-cell.jpg'))\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # openCV uses BGR for some reason\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning Datasets\n",
    "import os\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path) # Checks if image can be read\n",
    "            tip = imghdr.what(image_path) # Grabs extension of each file\n",
    "            if tip not in image_exts:\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = tf.keras.utils.image_dataset_from_directory('data') # Creates tf dataset (loads, resizes, batches data)\n",
    "data_iterator = data.as_numpy_iterator() # Creates iterator for data object\n",
    "batch = data_iterator.next() # Images and Labels. Shape = (32, 256, 256, 3)\n",
    "    # might need to drop batch size for GPU cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale Data [0,255] --> [0,1]\n",
    "data = data.map(lambda x,y:(x/255, y)) \n",
    "    # data.map allows for in-line pipeline \n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><center>In the images above, 0: Coin Cell and 1: Cylinder Cell</center></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Data\n",
    "num_batches = len(data)\n",
    "train_size = int(num_batches*0.7) \n",
    "val_size = int(num_batches*0.2)\n",
    "test_size = int(num_batches*0.1) \n",
    "\n",
    "while train_size + val_size + test_size < num_batches:\n",
    "    test_size += 1\n",
    "\n",
    "print(f\"Train Size: {train_size}, Validation Size: {val_size}, Test Size: {test_size}\")\n",
    "print(f\"Number of Batches: {num_batches}\")\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential # takes only one input as feed and expects one output\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "## Adding layers sequentially\n",
    "# Convulution Layers - using mainly relu activations \n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3))) # Input Layer\n",
    "model.add(MaxPooling2D()) # Returns max value over (2,2) region, reducing image size by 1/2\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten()) # reduces the input data into a single dimension instead of 2 dimensions.\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # One value as output (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])\n",
    "# hist.history "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color = 'red', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color = 'teal', label='val_loss')\n",
    "plt.plot(np.argmin((hist.history['val_loss'])), min(hist.history['val_loss']), color = 'green', label = 'Minimum Validation Loss', marker='*', linestyle = '')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model is overfitting - this will be key in actual sorting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "plt.plot(np.argmax((hist.history['val_accuracy'])), max(hist.history['val_accuracy']), color = 'green', label = 'Maximum Validation Accuracy', marker='*', linestyle = '')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "for batch in test.as_numpy_iterator(): # testing data\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "print(pre.result(), re.result(), acc.result())\n",
    "\n",
    "print(f\"Precision: {pre.result()}\")\n",
    "print(f\"Recall: {re.result()}\") \n",
    "print(f\"Accuracy: {acc.result()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Testing w/ own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(os.path.join('data','user-test', 'test1.jpeg'))\n",
    "img2 = cv2.imread(os.path.join('data','user-test', 'test2.jpeg'))\n",
    "resize1 = tf.image.resize(img1, (256,256))\n",
    "resize2 = tf.image.resize(img2, (256,256))\n",
    "\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(resize1.numpy().astype(int))\n",
    "axarr[0].set_title('Test Image 1')\n",
    "axarr[1].imshow(resize2.numpy().astype(int))\n",
    "axarr[1].set_title('Test Image 2')\n",
    "\n",
    "yhat1 = model.predict(np.expand_dims(resize1/255,0))\n",
    "print(yhat1)\n",
    "label1 = 'Coin Cell' if yhat1 < 0.5 else 'Cylinder Cell'\n",
    "yhat2 = model.predict(np.expand_dims(resize2/255,0))\n",
    "print(yhat2)\n",
    "label2 = 'Coin Cell' if yhat2 < 0.5 else 'Cylinder Cell'\n",
    "\n",
    "axarr[0].text(75, 50, label1, color='red')\n",
    "axarr[1].text(75, 50, label2, color='red')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
